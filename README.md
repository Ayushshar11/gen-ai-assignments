üìö Assignments Overview
Assignment 2 ‚Äì RNN/LSTM Encoder-Decoder Model
This assignment focuses on implementing a basic Encoder-Decoder architecture using Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) units.

Key tasks:

Understanding the theoretical foundation of RNNs, LSTMs, and encoder-decoder models

Implementing a sequence-to-sequence model in TensorFlow/Keras

Translating simple sequences (e.g., English to French)

Visualizing training loss

(Optional) Integrating an attention mechanism

üìÅ Directory: Assignment2/
Includes:

Jupyter Notebook or Python script

PDF/DOCX with answers to theoretical questions

Assignment 3 ‚Äì Retrieval-Augmented Generation using LangChain
This assignment focuses on building a Retrieval-Augmented Generation (RAG) pipeline using the LangChain framework. It demonstrates how to enhance the output of language models by grounding responses in external knowledge.

Key tasks:

Understanding the concept and architecture of RAG

Loading and chunking a local document

Generating and storing embeddings using OpenAI/HuggingFace/Ollama

Using FAISS or Chroma for vector storage

Querying using a retriever and generating answers using an LLM

Comparing standard LLM output with RAG-enhanced responses

(Optional) Customizing prompts with citations or structured output

üìÅ Directory: Assignment3/
Includes:

Jupyter Notebook or Python script

Local document used as the knowledge base

Logs of sample queries and results

üõ†Ô∏è How to Use
Clone the repository:

bash
Copy
Edit
git clone https://github.com/Ayushshar11/gen-ai-assignments.git
cd gen-ai-assignments
Navigate to the desired assignment folder:

Assignment2/ for RNN/LSTM-based model

Assignment3/ for RAG pipeline

Follow the instructions in each folder‚Äôs README to run the code.

üß∞ Technologies Used
Python

TensorFlow / Keras

LangChain

FAISS / Chroma

OpenAI / HuggingFace / Ollama

Jupyter Notebook



